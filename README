The idea came when I tried to clean up my old backups. I was looking for files
that I will still need and deleting duplicate backups. Since I used to
completely copy all my data to my backup drive every time I wanted to backup I
have a hell of a mess. I don't want to lose any data. Especially not my
pictures. I hope this will speed up cleaning. The goal is to identify duplicates
in my backups and thusly reduce the data that I have to check manually.

Since the script now uses a database for its collected data instead of having
everything in memory it should work even with huge amounts of files.
